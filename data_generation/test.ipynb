{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c553d0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from faker import Faker\n",
    "\n",
    "faker = Faker()\n",
    "\n",
    "n_users = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33aa1ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_df = pd.DataFrame({\n",
    "    \"user_id\": np.arange(1, n_users + 1),\n",
    "    \"gender\": np.random.choice([\"M\", \"F\"], size=n_users),\n",
    "    \"created_at\": pd.to_datetime(\"2019-01-01\") + pd.to_timedelta(np.random.randint(0, 2000, size=n_users), unit='D'),\n",
    "    \"num_orders\": np.random.choice([0,1,2,3,4], p=[0.2, 0.5, 0.2, 0.05, 0.05], size=n_users),\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ff0693b",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_df = users_df.loc[users_df.index.repeat(users_df['num_orders'])].copy()\n",
    "orders_df[\"order_id\"] = np.arange(1, len(orders_df) + 1)\n",
    "orders_df[\"order_created_at\"] = orders_df[\"created_at\"] + pd.to_timedelta(np.random.randint(1, 180, size=len(orders_df)), unit=\"D\")\n",
    "orders_df[\"status\"] = np.random.choice([\"Complete\", \"Cancelled\", \"Returned\", \"Processing\", \"Shipped\"], \n",
    "                                       p=[0.25, 0.15, 0.1, 0.2, 0.3], size=len(orders_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5c090d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_of_names = [[faker.first_name(), faker.last_name_nonbinary()] for _ in range(1_000_000)]\n",
    "\n",
    "first_names = np.array([faker.uuid4() for _ in range(1_000_000)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e18dc258",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import pandas as pd\n",
    "\n",
    "def generate_chunk(seed_offset, n):\n",
    "    from faker import Faker\n",
    "    faker = Faker()\n",
    "    Faker.seed(seed_offset)\n",
    "    data = [(faker.first_name(), faker.last_name()) for _ in range(n)]\n",
    "    return data\n",
    "\n",
    "def parallel_generate(total=1_000_000, workers=6):\n",
    "    chunk_size = total // workers\n",
    "    with ProcessPoolExecutor(max_workers=workers) as ex:\n",
    "        chunks = list(ex.map(generate_chunk, range(workers), [chunk_size]*workers))\n",
    "    all_data = [item for sublist in chunks for item in sublist]\n",
    "    return pd.DataFrame(all_data, columns=[\"first_name\", \"last_name\"])\n",
    "\n",
    "df = parallel_generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "44482533",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(858869)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dupes = df.duplicated(subset=[\"first_name\", \"last_name\"], keep=False)\n",
    "dupes.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ddc4b613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_names.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f3a34a89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['711b4562-c32a-4c0f-a433-51f0c4a36dea',\n",
       "       'f63f9ca4-71c9-46e7-90ea-d457e997010f',\n",
       "       '3b2ce5a5-d91d-40ab-8122-92d6ad19ebfc', ...,\n",
       "       '12887df5-36c2-4794-835d-8a2c9a26f43d',\n",
       "       '6374a4f7-5067-462c-b893-bc86c60418e4',\n",
       "       '5ebae0ba-710b-418e-baf3-c093d0baef5c'],\n",
       "      shape=(1000000,), dtype='<U36')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b91b61fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "has_duplicates = np.unique(first_names).size != first_names.size\n",
    "print(has_duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "280578fd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[54]\u001b[39m\u001b[32m, line 60\u001b[39m\n\u001b[32m     56\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m users_df\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     59\u001b[39m     \u001b[38;5;66;03m# file path in ./data_generation/data\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m     file_path = os.path.dirname(os.path.abspath(\u001b[34;43m__file__\u001b[39;49m))\n\u001b[32m     62\u001b[39m     world_pop_df = pd.read_csv(os.path.join(file_path, \u001b[33m\"\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mworld_pop.csv\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m     63\u001b[39m     distribution_centers_df = pd.read_csv(os.path.join(file_path, \u001b[33m\"\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mdistribution_centers.csv\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "\u001b[31mNameError\u001b[39m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from faker import Faker\n",
    "import re\n",
    "import os\n",
    "\n",
    "class DataGenerator:\n",
    "    def __init__(self, n_users:int, seed:int = 42):\n",
    "        self.n_users = n_users\n",
    "        self.faker = Faker()\n",
    "        Faker.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    @staticmethod\n",
    "    def sanitize(arr: np.ndarray) -> np.ndarray:\n",
    "        return np.vectorize(lambda x: re.sub(r\"[^a-zA-Z]\", \"\", x).lower())(arr)\n",
    "    \n",
    "    def generate_addresses(self, LOC_DATA:pd.DataFrame) -> pd.DataFrame:\n",
    "        weights = LOC_DATA['population'] / LOC_DATA['population'].sum()\n",
    "        # sample n_users based on population weights\n",
    "        df_sampled = LOC_DATA.sample(n=self.n_users, weights=weights, replace=True).reset_index(drop=True)\n",
    "        # generate street addresses\n",
    "        df_sampled['street'] = [self.faker.street_address() for _ in range(self.n_users)]\n",
    "\n",
    "        # return n_users sampled addresses based on population weights\n",
    "        return df_sampled\n",
    "    \n",
    "    def generate_users(self, addresses: pd.DataFrame) -> pd.DataFrame:\n",
    "        gender_list = np.random.choice([\"M\", \"F\"], size=self.n_users)\n",
    "\n",
    "        # generate names based on gender vectorized\n",
    "        first_names = np.where(gender_list == \"M\",\n",
    "                               np.array([self.faker.first_name_male() for _ in range(self.n_users)]),\n",
    "                               np.array([self.faker.first_name_female() for _ in range(self.n_users)]))\n",
    "        last_names = [self.faker.last_name_nonbinary() for _ in range(self.n_users)]\n",
    "\n",
    "        uuids = [self.faker.uuid4() for _ in range(self.n_users)]\n",
    "\n",
    "        emails = np.char.lower(self.sanitize(\n",
    "            np.array(first_names)) + \".\" + self.sanitize(np.array(last_names)) + \"@example.com\"\n",
    "            )\n",
    "        \n",
    "        users_df = pd.DataFrame({\n",
    "            \"id\": np.arange(1, self.n_users + 1),\n",
    "            \"uuid\": uuids,\n",
    "            \"first_name\": first_names,\n",
    "            \"last_name\": last_names,\n",
    "            \"email\": emails,\n",
    "            \"age\": np.random.randint(18, 70, size=self.n_users),\n",
    "            \"gender\": gender_list,\n",
    "            **addresses.to_dict(orient='list'),\n",
    "            \"num_of_orders\": np.random.choice([0,1,2,3,4], p=[0.2, 0.5, 0.2, 0.05, 0.05], size=self.n_users),\n",
    "            \"created_at\": pd.to_datetime(\"2019-01-01\") + pd.to_timedelta((np.random.rand(self.n_users) ** 2) * 365 * 5, unit='d'), # Bias towards older dates\n",
    "        })\n",
    "        self.users_df = users_df\n",
    "        return users_df\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    # file path in ./data_generation/data\n",
    "    file_path = os.path.dirname(os.path.abspath(__file__))\n",
    "\n",
    "    world_pop_df = pd.read_csv(os.path.join(file_path, \"data\", \"world_pop.csv\"))\n",
    "    distribution_centers_df = pd.read_csv(os.path.join(file_path, \"data\", \"distribution_centers.csv\"))\n",
    "\n",
    "    n_users = 2\n",
    "    data_generator = DataGenerator(n_users=n_users, seed=42)\n",
    "    addresses = data_generator.generate_addresses(LOC_DATA=world_pop_df)\n",
    "    users_df = data_generator.generate_users(addresses=addresses)\n",
    "    print(users_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87236e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analytics-pipeline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
